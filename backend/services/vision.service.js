import { google } from 'googleapis';
import { oauth2Client } from '../config/google.config.js';
import sharp from 'sharp';
import axios from 'axios';

/**
 * Servi√ßo para an√°lise de imagens com Google Cloud Vision API
 */
class VisionService {
  constructor() {
    this.isEnabled = !!process.env.GOOGLE_CLOUD_VISION_ENABLED;
    this.maxImageSize = 4 * 1024 * 1024; // 4MB - limite seguro para Vision API
    this.apiEndpoint = 'https://vision.googleapis.com/v1/images:annotate';
  }

  /**
   * Redimensiona imagem se for muito grande
   * @param {Buffer} imageBuffer - Buffer da imagem original
   * @returns {Promise<Buffer>} Buffer da imagem processada
   */
  async processImageBuffer(imageBuffer) {
    try {
      const sizeInMB = imageBuffer.length / 1024 / 1024;
      console.log(`  üìè Tamanho original: ${sizeInMB.toFixed(2)}MB`);

      // SEMPRE redimensiona imagens grandes para garantir que passem
      if (imageBuffer.length > this.maxImageSize) {
        console.log(`  ‚ö†Ô∏è  Imagem grande, redimensionando...`);
      } else {
        console.log(`  ‚úÖ Tamanho OK, mas redimensionando por seguran√ßa...`);
      }

      // SEMPRE redimensiona para garantir compatibilidade
      // M√°ximo 1280px no lado maior para garantir que fique pequeno
      const processedBuffer = await sharp(imageBuffer)
        .resize(1280, 1280, { 
          fit: 'inside',
          withoutEnlargement: true 
        })
        .jpeg({ quality: 80 }) // JPEG com qualidade 80%
        .toBuffer();

      const newSizeInMB = processedBuffer.length / 1024 / 1024;
      console.log(`  ‚úÖ Nova imagem: ${newSizeInMB.toFixed(2)}MB`);
      
      return processedBuffer;
    } catch (error) {
      // Se for erro de HEIC ou formato n√£o suportado, usa imagem original
      if (error.message.includes('heif') || error.message.includes('compression format')) {
        console.log('  ‚ö†Ô∏è  Formato HEIC/n√£o suportado, usando imagem original...');
        return imageBuffer;
      }
      
      console.error('  ‚ùå Erro ao processar imagem:', error.message);
      // Tenta um redimensionamento mais agressivo
      try {
        console.log('  üîÑ Tentando redimensionamento mais agressivo...');
        const fallbackBuffer = await sharp(imageBuffer)
          .resize(800, 800, { fit: 'inside' })
          .jpeg({ quality: 70 })
          .toBuffer();
        console.log(`  ‚úÖ Fallback: ${(fallbackBuffer.length / 1024 / 1024).toFixed(2)}MB`);
        return fallbackBuffer;
      } catch (fallbackError) {
        console.log('  ‚ö†Ô∏è  Fallback falhou, usando imagem original...');
        return imageBuffer;
      }
    }
  }

  /**
   * Analisa uma imagem para detectar rostos e emo√ß√µes
   * @param {Buffer} imageBuffer - Buffer da imagem
   * @returns {Promise<Object>} Resultado da an√°lise
   */
  async analyzeImage(imageBuffer) {
    if (!this.isEnabled) {
      console.log('Vision API desabilitada. Pulando an√°lise.');
      return this.getEmptyAnalysis();
    }

    try {
      // Processa a imagem (redimensiona se necess√°rio)
      const processedBuffer = await this.processImageBuffer(imageBuffer);
      const base64Image = processedBuffer.toString('base64');
      
      // Obter token de acesso
      const { token } = await oauth2Client.getAccessToken();
      
      // Fazer requisi√ß√£o direta via API REST
      const requestBody = {
        requests: [{
          image: { content: base64Image },
          features: [
            { type: 'FACE_DETECTION', maxResults: 10 },
            { type: 'LABEL_DETECTION', maxResults: 10 },
            { type: 'SAFE_SEARCH_DETECTION' }
          ]
        }]
      };

      const response = await axios.post(
        this.apiEndpoint,
        requestBody,
        {
          headers: {
            'Authorization': `Bearer ${token}`,
            'Content-Type': 'application/json'
          },
          maxContentLength: Infinity,
          maxBodyLength: Infinity
        }
      );

      const result = response.data.responses[0];
      return this.processAnalysisResult(result);
      
    } catch (error) {
      console.error('Erro na an√°lise Vision API:', error.response?.data || error.message);
      // Em caso de erro, retorna an√°lise vazia ao inv√©s de falhar
      return this.getEmptyAnalysis();
    }
  }

  /**
   * Processa resultado da an√°lise do Vision API
   * @param {Object} result - Resultado raw do Vision API
   * @returns {Object} An√°lise processada
   */
  processAnalysisResult(result) {
    const faces = result.faceAnnotations || [];
    const labels = result.labelAnnotations || [];
    const safeSearch = result.safeSearchAnnotation || {};

    // Analisa emo√ß√µes dos rostos detectados
    const emotionAnalysis = this.analyzeEmotions(faces);

    return {
      facesDetected: faces.length,
      emotions: emotionAnalysis,
      labels: labels.map(label => ({
        description: label.description,
        score: label.score,
        confidence: label.confidence
      })),
      safeSearch: {
        adult: safeSearch.adult,
        violence: safeSearch.violence,
        racy: safeSearch.racy
      }
    };
  }

  /**
   * Analisa emo√ß√µes predominantes nos rostos detectados
   * @param {Array} faces - Array de rostos detectados
   * @returns {Object} An√°lise de emo√ß√µes
   */
  analyzeEmotions(faces) {
    if (!faces || faces.length === 0) {
      return this.getEmptyEmotions();
    }

    // Conta likelihood de cada emo√ß√£o
    const emotionCounts = {
      joy: { VERY_LIKELY: 0, LIKELY: 0, POSSIBLE: 0, UNLIKELY: 0, VERY_UNLIKELY: 0 },
      sorrow: { VERY_LIKELY: 0, LIKELY: 0, POSSIBLE: 0, UNLIKELY: 0, VERY_UNLIKELY: 0 },
      anger: { VERY_LIKELY: 0, LIKELY: 0, POSSIBLE: 0, UNLIKELY: 0, VERY_UNLIKELY: 0 },
      surprise: { VERY_LIKELY: 0, LIKELY: 0, POSSIBLE: 0, UNLIKELY: 0, VERY_UNLIKELY: 0 }
    };

    faces.forEach(face => {
      if (face.joyLikelihood) emotionCounts.joy[face.joyLikelihood]++;
      if (face.sorrowLikelihood) emotionCounts.sorrow[face.sorrowLikelihood]++;
      if (face.angerLikelihood) emotionCounts.anger[face.angerLikelihood]++;
      if (face.surpriseLikelihood) emotionCounts.surprise[face.surpriseLikelihood]++;
    });

    // Determina emo√ß√£o predominante
    const predominant = this.getPredominantEmotion(emotionCounts, faces.length);

    return {
      joyLikelihood: predominant.joy,
      sorrowLikelihood: predominant.sorrow,
      angerLikelihood: predominant.anger,
      surpriseLikelihood: predominant.surprise,
      predominantEmotion: predominant.main
    };
  }

  /**
   * Determina emo√ß√£o predominante
   * @param {Object} emotionCounts - Contagem de emo√ß√µes
   * @param {number} totalFaces - Total de rostos
   * @returns {Object} Emo√ß√£o predominante
   */
  getPredominantEmotion(emotionCounts, totalFaces) {
    const getLikelihood = (emotion) => {
      const counts = emotionCounts[emotion];
      if (counts.VERY_LIKELY > totalFaces * 0.5) return 'VERY_LIKELY';
      if (counts.VERY_LIKELY + counts.LIKELY > totalFaces * 0.5) return 'LIKELY';
      if (counts.VERY_LIKELY + counts.LIKELY + counts.POSSIBLE > totalFaces * 0.3) return 'POSSIBLE';
      if (counts.VERY_UNLIKELY > totalFaces * 0.5) return 'VERY_UNLIKELY';
      return 'UNLIKELY';
    };

    const likelihoods = {
      joy: getLikelihood('joy'),
      sorrow: getLikelihood('sorrow'),
      anger: getLikelihood('anger'),
      surprise: getLikelihood('surprise')
    };

    // Determina qual √© a principal
    let mainEmotion = 'neutral';
    if (likelihoods.joy === 'VERY_LIKELY' || likelihoods.joy === 'LIKELY') {
      mainEmotion = 'joy';
    } else if (likelihoods.sorrow === 'VERY_LIKELY' || likelihoods.sorrow === 'LIKELY') {
      mainEmotion = 'sorrow';
    } else if (likelihoods.anger === 'VERY_LIKELY' || likelihoods.anger === 'LIKELY') {
      mainEmotion = 'anger';
    } else if (likelihoods.surprise === 'VERY_LIKELY' || likelihoods.surprise === 'LIKELY') {
      mainEmotion = 'surprise';
    }

    return {
      ...likelihoods,
      main: mainEmotion
    };
  }

  /**
   * Retorna an√°lise vazia (quando Vision API est√° desabilitada ou falha)
   */
  getEmptyAnalysis() {
    return {
      facesDetected: 0,
      emotions: this.getEmptyEmotions(),
      labels: [],
      safeSearch: {}
    };
  }

  /**
   * Retorna emo√ß√µes vazias
   */
  getEmptyEmotions() {
    return {
      joyLikelihood: 'UNKNOWN',
      sorrowLikelihood: 'UNKNOWN',
      angerLikelihood: 'UNKNOWN',
      surpriseLikelihood: 'UNKNOWN',
      predominantEmotion: 'neutral'
    };
  }
}

export default new VisionService();
